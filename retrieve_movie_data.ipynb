{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries and Set Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables from the .env in the local environment\n",
    "load_dotenv()\n",
    "\n",
    "nyt_api_key = os.getenv(\"NYT_API_KEY\")\n",
    "tmdb_api_key = os.getenv(\"TMDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the New York Times API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base URL\n",
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "# Filter for movie reviews with \"love\" in the headline\n",
    "# section_name should be \"Movies\"\n",
    "# type_of_material should be \"Review\"\n",
    "filter_query = 'section_name:\"Movies\" AND type_of_material:\"Review\" AND headline:\"love\"'\n",
    "# Use a sort filter, sort by newest\n",
    "sort = \"newest\"\n",
    "# Select the following fields to return:\n",
    "# headline, web_url, snippet, source, keywords, pub_date, byline, word_count\n",
    "field_list = \"headline,web_url,snippet,source,keywords,pub_date,byline,word_count\"\n",
    "# Search for reviews published between a begin and end date\n",
    "begin_date = \"20130101\"\n",
    "end_date = \"20230531\"\n",
    "# Build URL\n",
    "query_url = (\n",
    "    f\"{url}api-key={nyt_api_key}&begin_date={begin_date}&end_date={end_date}&fq={filter_query}&sort={sort}&fl={field_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred on page 1 with offset 0: 'response'\n"
     ]
    }
   ],
   "source": [
    "# create a list to store the reviews\n",
    "reviews_list = ([])  \n",
    "# Attempt to retrieve 200 reviews by iterating through 20 pages starting at 0 (10 results per page)\n",
    "for page in range(2):  # NYT API limits results to 10 per page, 20 pages = 200 results\n",
    "    offset = page * 2\n",
    "    full_url = f\"{url}api-key={nyt_api_key}&q=love&fq={filter_query}&begin_date={begin_date}&end_date={end_date}&sort={sort}&fl={field_list}&page={page}\"\n",
    "    \n",
    "    response = requests.get(full_url)\n",
    "    # Make a \"GET\" requyest and retrieve the JSON\n",
    "    # reviews = requests.get(url).json()\n",
    "# print(json.dumps(reviews, indent=4))\n",
    "    time.sleep(6)  #  rate limits per documentation\n",
    "\n",
    "    try:\n",
    "        reviews = response.json()\n",
    "        if reviews[\"response\"][\"docs\"]:\n",
    "            reviews_list.extend(reviews[\"response\"][\"docs\"])\n",
    "            print(f\"Page {page + 1} processed, offset {offset}\")\n",
    "        else:\n",
    "            print(f\"No more results found at page {page + 1}, stopping.\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred on page {page + 1} with offset {offset}: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Coonfirm 200 reviews were retrieved\n",
    "print(len(reviews_list))\n",
    "\n",
    "# Preview the first 5 results in JSON format\n",
    "first_five = reviews_list[:5]\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "json_data = json.dumps(first_five, indent=4)\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web_url</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>keywords</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>word_count</th>\n",
       "      <th>headline.main</th>\n",
       "      <th>headline.kicker</th>\n",
       "      <th>headline.content_kicker</th>\n",
       "      <th>headline.print_headline</th>\n",
       "      <th>headline.name</th>\n",
       "      <th>headline.seo</th>\n",
       "      <th>headline.sub</th>\n",
       "      <th>byline.original</th>\n",
       "      <th>byline.person</th>\n",
       "      <th>byline.organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.nytimes.com/2023/05/25/movies/the-...</td>\n",
       "      <td>A gynecologist and her patient form a horrifyi...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Movies', 'rank'...</td>\n",
       "      <td>2023-05-25T11:00:03+0000</td>\n",
       "      <td>295</td>\n",
       "      <td>‘The Attachment Diaries’ Review: Love, Sick</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The Attachment Diaries</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>By Jeannette Catsoulis</td>\n",
       "      <td>[{'firstname': 'Jeannette', 'middlename': None...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nytimes.com/2023/05/04/movies/what...</td>\n",
       "      <td>Two childhood friends navigate cultural differ...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Movies', 'rank'...</td>\n",
       "      <td>2023-05-04T17:16:45+0000</td>\n",
       "      <td>287</td>\n",
       "      <td>Review: ‘What’s Love Got to Do With It?’ Proba...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>What’s Love Got to Do With It?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>By Jeannette Catsoulis</td>\n",
       "      <td>[{'firstname': 'Jeannette', 'middlename': None...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nytimes.com/2023/05/04/movies/you-...</td>\n",
       "      <td>Religion comes between two girls falling in lo...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Movies', 'rank'...</td>\n",
       "      <td>2023-05-04T11:00:08+0000</td>\n",
       "      <td>294</td>\n",
       "      <td>‘You Can Live Forever’ Review: Do You Love Me ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>You Can Live Forever</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>By Elisabeth Vincentelli</td>\n",
       "      <td>[{'firstname': 'Elisabeth', 'middlename': None...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             web_url  \\\n",
       "0  https://www.nytimes.com/2023/05/25/movies/the-...   \n",
       "1  https://www.nytimes.com/2023/05/04/movies/what...   \n",
       "2  https://www.nytimes.com/2023/05/04/movies/you-...   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  A gynecologist and her patient form a horrifyi...  The New York Times   \n",
       "1  Two childhood friends navigate cultural differ...  The New York Times   \n",
       "2  Religion comes between two girls falling in lo...  The New York Times   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{'name': 'subject', 'value': 'Movies', 'rank'...   \n",
       "1  [{'name': 'subject', 'value': 'Movies', 'rank'...   \n",
       "2  [{'name': 'subject', 'value': 'Movies', 'rank'...   \n",
       "\n",
       "                   pub_date  word_count  \\\n",
       "0  2023-05-25T11:00:03+0000         295   \n",
       "1  2023-05-04T17:16:45+0000         287   \n",
       "2  2023-05-04T11:00:08+0000         294   \n",
       "\n",
       "                                       headline.main headline.kicker  \\\n",
       "0        ‘The Attachment Diaries’ Review: Love, Sick            None   \n",
       "1  Review: ‘What’s Love Got to Do With It?’ Proba...            None   \n",
       "2  ‘You Can Live Forever’ Review: Do You Love Me ...            None   \n",
       "\n",
       "  headline.content_kicker         headline.print_headline headline.name  \\\n",
       "0                    None          The Attachment Diaries          None   \n",
       "1                    None  What’s Love Got to Do With It?          None   \n",
       "2                    None            You Can Live Forever          None   \n",
       "\n",
       "  headline.seo headline.sub           byline.original  \\\n",
       "0         None         None    By Jeannette Catsoulis   \n",
       "1         None         None    By Jeannette Catsoulis   \n",
       "2         None         None  By Elisabeth Vincentelli   \n",
       "\n",
       "                                       byline.person byline.organization  \n",
       "0  [{'firstname': 'Jeannette', 'middlename': None...                None  \n",
       "1  [{'firstname': 'Jeannette', 'middlename': None...                None  \n",
       "2  [{'firstname': 'Elisabeth', 'middlename': None...                None  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert reviews_list to a Pandas DataFrame using json_normalize()\n",
    "reviews_df = pd.json_normalize(reviews_list)\n",
    "\n",
    "# Optionally, preview the first few rows of the DataFrame\n",
    "#print(reviews_df.head(3))\n",
    "reviews_df.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the title from the \"headline.main\" column and\n",
    "# save it to a new column \"title\"\n",
    "# Title is between unicode characters \\u2018 and \\u2019.\n",
    "# End string should include \" Review\" to avoid cutting title early\n",
    "# Using \"\\u2019 Review\" to find the end of the title does not work too well because often the string in \"headline.main\" does not contain \"\\u2019 Review\".\n",
    "reviews_df[\"title\"] = reviews_df[\"headline.main\"].apply(\n",
    "    lambda st: st[st.find(\"\\u2018\") + 1 : st.find(\"\\u2019 \")]\n",
    ")\n",
    "# Sometimes we end up with a trailing comma. Remove it.\n",
    "reviews_df[\"title\"] = reviews_df[\"title\"].str.rstrip(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'name' and 'value' from items in \"keywords\" column\n",
    "def extract_keywords(keyword_list):\n",
    "    extracted_keywords = \"\"\n",
    "    for item in keyword_list:\n",
    "        # Extract 'name' and 'value'\n",
    "        keyword = f\"{item['name']}: {item['value']};\"\n",
    "        # Append the keyword item to the extracted_keywords list\n",
    "        extracted_keywords += keyword\n",
    "    return extracted_keywords\n",
    "\n",
    "# Fix the \"keywords\" column by converting cells from a list to a string\n",
    "reviews_df[\"keywords\"] = reviews_df[\"keywords\"].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list from the \"title\" column using to_list()\n",
    "# These titles will be used in the query for The Movie Database\n",
    "titles_list = reviews_df[\"title\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access The Movie Database API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare The Movie Database query\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.themoviedb.org/3/search/movie?query=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m tmdb_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m&api_key=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtmdb_api_key\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "# Prepare The Movie Database query\n",
    "url = \"https://api.themoviedb.org/3/search/movie?query=\"\n",
    "tmdb_api_key = \"&api_key=\" + tmdb_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the results\n",
    "import random\n",
    "import time\n",
    "tmdb_movies_list = []   \n",
    "\n",
    "# Create a request counter to sleep the requests after a multiple\n",
    "# of 50 requests\n",
    "request_counter= 1\n",
    "\n",
    "# Loop through the titles\n",
    "for title in titles_list:\n",
    "    # Check if we need to sleep before making a request\n",
    "    if request_counter % 50 == 0:\n",
    "        # Sleep for a random time between 1 and 5 seconds\n",
    "        time.sleep(1)\n",
    "        print(\"Sleeping for 1 second\")\n",
    "\n",
    "    # Add 1 to the request counter\n",
    "    request_counter += 1    \n",
    "\n",
    "    # Perform a \"GET\" request for The Movie Database\n",
    "    tmdb_response = requests.get(url + title + tmdb_key_string) .json()\n",
    "\n",
    "    # Include a try clause to search for the full movie details.\n",
    "    # Use the except clause to print out a statement if a movie\n",
    "    # is not found.\n",
    "    try:\n",
    "        # Get movie id\n",
    "        movie_id = tmdb_response[\"results\"][0][\"id\"]\n",
    "\n",
    "        # Make a request for a the full movie details\n",
    "        movie_details_url = f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={tmdb_api_key}\"\n",
    "\n",
    "        # Execute \"GET\" request with url\n",
    "        tmdb_response_details = requests.get(movie_details_url).json()\n",
    "\n",
    "        # Extract the genre names into a list\n",
    "        genres = [tmdb_response_details['genres'][i]['name'] for i in range(len(tmdb_response_details['genres']))]\n",
    "\n",
    "        # Extract the spoken_languages' English name into a list\n",
    "        spoken_languages = [tmdb_response_details['spoken_languages'][i]['english_name'] for i in range(len(tmdb_response_details['spoken_languages']))]\n",
    "\n",
    "        # Extract the production_countries' name into a list\n",
    "        production_countries = [tmdb_response_details['production_countries'][i]['name'] for i in range(len(tmdb_response_details['production_countries']))]\n",
    "\n",
    "        # Add the relevant data to a dictionary and\n",
    "        # append it to the tmdb_movies_list list\n",
    "        dict_movie_details = {'title': title,\n",
    "                              'original_title': tmdb_response_details['original_title'],\n",
    "                              'budget': tmdb_response_details['budget'],\n",
    "                              'original_language': tmdb_response_details['original_language'],\n",
    "                              'homepage': tmdb_response_details['homepage'],\n",
    "                              'overview': tmdb_response_details['overview'],\n",
    "                              'popularity': tmdb_response_details['popularity'],\n",
    "                              'runtime': tmdb_response_details['runtime'],\n",
    "                              'revenue': tmdb_response_details['revenue'],\n",
    "                              'release_date': tmdb_response_details['release_date'],\n",
    "                              'vote_average': tmdb_response_details['vote_average'],\n",
    "                              'vote_count': tmdb_response_details['vote_count'],\n",
    "                              'genres': genres,\n",
    "                              'spoken_languages': spoken_languages,\n",
    "                              'production_countries': production_countries}\n",
    "        tmdb_movies_list.append(dict_movie_details)\n",
    "\n",
    "        # Print out the title that was found\n",
    "        print(f'The movie called \"{title}\" was found.')\n",
    "    except:\n",
    "        print(f'NOT FOUND: \"{title}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "print(json.dumps(tmdb_movies_list[:5], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results to a DataFrame\n",
    "tmdb_movies_df = pd.DataFrame(tmdb_movies_list)\n",
    "tmdb_movies_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Clean the Data for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the New York Times reviews and TMDB DataFrames on title\n",
    "merged_df = pd.merge(tmdb_movies_df, reviews_df, on=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove list brackets and quotation marks on the columns containing lists\n",
    "# Create a list of the columns that need fixing\n",
    "columns_fix = ['genres', 'spoken_language', 'production_countries',]  \n",
    "\n",
    "# Create a list of characters to remove\n",
    "characters_remove = ['[', ']', '\"']\n",
    "\n",
    "# Loop through the list of columns to fix\n",
    "for col in columns_fix:\n",
    "    # Convert the column to type 'str'\n",
    "    merged_df[col] = merged_df[col].astype(str)\n",
    "\n",
    "    # Loop through characters to remove\n",
    "    for char in characters_remove:\n",
    "        # Remove the character\n",
    "        merged_df[col] = merged_df[col].str.replace(char, '')\n",
    "\n",
    "# Display the fixed DataFrame\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"byline.person\" column\n",
    "merged_df = merged_df.drop(columns=[\"byline.person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate rows and reset index\n",
    "print(merged_df.shape)\n",
    "merged_df = merged_df.drop_duplicates(inplace=True)\n",
    "print(merged_df.shape)\n",
    "merged_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV without the index\n",
    "merged_df.to_csv('output/movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
